{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install git+https://github.com/huggingface/speechbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "concatenated_librispeech = load_dataset(\n",
    "    \"sanchit-gandhi/concatenated_librispeech\", split=\"train\", streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "asr_pipeline = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-base\",\n",
    ")\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "diarization_pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"YOUR TOKEN\")\n",
    "\n",
    "from speechbox import ASRDiarizationPipeline\n",
    "pipeline = ASRDiarizationPipeline(\n",
    "    asr_pipeline=asr_pipeline, diarization_pipeline=diarization_pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now instantiate our combined diarization plus transcription pipeline, by passing the diarization model and ASR model to the ASRDiarizationPipeline class:\n",
    "def tuple_to_string(start_end_tuple, ndigits=3):\n",
    "    return str((round(start_end_tuple[0], ndigits), round(start_end_tuple[1], ndigits)))\n",
    "\n",
    "\n",
    "def format_as_transcription(raw_segments):\n",
    "    return [chunk for chunk in raw_segments]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate file but idk how to separate it ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a \n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "class ComplexModel(nn.Module):\n",
    "    def __init__(self, input_size=2*768, hidden_size=384):\n",
    "        super(ComplexModel, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Fully connected layer 1\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # Fully connected layer 2\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size) # Fully connected layer 3\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size) # Fully connected layer 4\n",
    "        self.fc5 = nn.Linear(hidden_size, 1)           # Output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()     # ReLU activation function\n",
    "        self.sigmoid = nn.Sigmoid() # Sigmoid activation function\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.4) # Dropout layer to prevent overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def main():\n",
    "device = pt.device(\"mps\") if pt.backends.mps.is_available() else pt.device(\"cpu\")\n",
    "embedding_classifier = pt.load(\"is_conversation_embedding_classifier_doubles.pt\")\n",
    "embedding_classifier.to(device)\n",
    "embedding_classifier.eval()\n",
    "# Step 2: Create the embeddings\n",
    "sent_transf = SentenceTransformer(\"avsolatorio/GIST-Embedding-v0\", revision=None)\n",
    "sent_transf.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapt Diarization Outputs to be inputed into model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transcript is composed of turns. Each turn represents one participant's action in the conversation, which can include sending a message, asking a question, making a statement, etc. Turns are organized sequentially in the transcript to reflect the flow of the conversation. So, in essence, a transcript is a collection of turns exchanged between participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Turn:\n",
    "    def __init__(self, turn) -> None:\n",
    "        self.speaker = turn['speaker']\n",
    "        self.text = turn['text']\n",
    "        self.timestamp = turn['timestamp']\n",
    "        self.embedding = sent_transf.encode(self.text)\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.speaker} {self.timestamp}: {self.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carito (0.3, 0.4): esto es una prueba\n"
     ]
    }
   ],
   "source": [
    "hola = Turn({'speaker': 'Carito', 'text': 'esto es una prueba', 'timestamp': (0.3, 0.4)})\n",
    "print(hola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexTranscript:\n",
    "    def __init__(self, transcript):\n",
    "        self.history: list[Turn] = []\n",
    "\n",
    "        for t in transcript:\n",
    "            new = Turn(t)\n",
    "            self.history.append(new)\n",
    "\n",
    "\n",
    "    def merge(self, transcript):\n",
    "        for t in transcript:\n",
    "            new = Turn(t)\n",
    "            self.history.append(new)\n",
    "\n",
    "        self.history = sorted(self.history, key=lambda x: x.timestamp[0])\n",
    "\n",
    "    def fake_merge(self):\n",
    "        timestamp = [\n",
    "            (1, 3), \n",
    "            (3,6), \n",
    "            (6,9), \n",
    "            (9,12), \n",
    "            (12,15), \n",
    "            (15,18), \n",
    "            (18,21)\n",
    "        ]\n",
    "        text = [\n",
    "            \"What's the name of your dog?\", \n",
    "            \"Her name is Mila, she is a bernaddoodle\", \n",
    "            \"Oh that is so cute! My dog's name is Max.\", \n",
    "            \"I had a dog named Max once, but he passed away when I was a kid.\", \n",
    "            \"Really? That is so sad.\",\n",
    "            \"Yeah, it was tough losing him, but now Mila brings so much joy into my life.\",\n",
    "            \"I am so glad to hear that!\"\n",
    "        ]\n",
    "        \n",
    "        speaker = [\n",
    "            \"Speaker A\",\n",
    "            \"Speaker B\",\n",
    "            \"Speaker A\",\n",
    "            \"Speaker B\",\n",
    "            \"Speaker A\",\n",
    "            \"Speaker B\",\n",
    "            \"Speaker A\",\n",
    "        ]\n",
    "\n",
    "        \n",
    "        for i in range(7):\n",
    "            fake_raw = {'speaker': speaker[i], 'text': text[i], 'timestamp':timestamp[i]}\n",
    "            fake_turn = Turn(fake_raw)\n",
    "            self.history.append(fake_turn)\n",
    "\n",
    "        self.history = sorted(self.history, key=lambda x: x.timestamp[0])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.history)\n",
    "    \n",
    "    # def expire_speakers(self, conversation_members, curr_time):\n",
    "    #     for speaker, expiry_time in conversation_members.items():\n",
    "    #         if curr_time > expiry_time:\n",
    "    #             conversation_members.pop(speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "# Load the MP3 file\n",
    "\n",
    "def process_audio(filename1 = \"Audios/Lady Yum.m4a\", filename2 = \"Audios/Lady Yum.m4a\") -> ComplexTranscript: \n",
    "    audio1, _ = librosa.load(filename1, sr=16000)\n",
    "    outputs1 = pipeline(audio1.copy())\n",
    "    transcript1 = format_as_transcription(outputs1)\n",
    "    \n",
    "    the_transcript = ComplexTranscript(transcript1)\n",
    "\n",
    "    # audio2, _ = librosa.load(filename1, sr=16000)\n",
    "    # outputs2 = pipeline(audio2.copy())\n",
    "    # transcript2 = format_as_transcription(outputs2)\n",
    "    \n",
    "    the_transcript.fake_merge()\n",
    "\n",
    "    return the_transcript\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = process_audio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, t: Turn) -> None:\n",
    "        self.history: list[Turn] = [t]\n",
    "        self.members: list[dict[str,float]]= {t.speaker:t.timestamp[1]}\n",
    "        self.last: Turn = t\n",
    "\n",
    "    def add(self, t: Turn) -> None:\n",
    "        self.history.append(t)\n",
    "        self.members[t.speaker] = t.timestamp[1]\n",
    "        self.last = t\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return str(self.members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_two_embeddings(e1, e2):\n",
    "    e = pt.tensor(np.concatenate((e1, e2)))\n",
    "    return embedding_classifier(e.to(device))[0].item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source for time tolerance\n",
    "https://gtr.ukri.org/projects?ref=AH%2FF018908%2F1#:~:text=Participants%20in%20a%20conversation%20often,with%20that%20of%20another%20talker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking two embeddings  Hello Antonio. &&&&  Hey! 0.9977649450302124\n",
      "Checking two embeddings What's the name of your dog? &&&&  Hey! 0.9963232278823853\n",
      "Checking two embeddings What's the name of your dog? &&&& Her name is Mila, she is a bernaddoodle 0.9710028171539307\n",
      "Checking two embeddings  Hey! &&&&  How are you today? 0.902826189994812\n",
      "Checking two embeddings Her name is Mila, she is a bernaddoodle &&&& Oh that is so cute! My dog's name is Max. 0.8712490200996399\n",
      "Checking two embeddings  How are you today? &&&&  I'm good. You? 0.9897275567054749\n",
      "Checking two embeddings  I'm good. You? &&&&  I'm great. What did you do today? 0.9887930750846863\n",
      "Checking two embeddings Oh that is so cute! My dog's name is Max. &&&&  I'm great. What did you do today? 0.9691892266273499\n",
      "Checking two embeddings Oh that is so cute! My dog's name is Max. &&&& I had a dog named Max once, but he passed away when I was a kid. 0.07672849297523499\n",
      "Checking two embeddings  I'm great. What did you do today? &&&&  I went for a long walk. 0.17657208442687988\n",
      "Checking two embeddings I had a dog named Max once, but he passed away when I was a kid. &&&&  I went for a long walk. 0.00023867341224104166\n",
      "Checking two embeddings I had a dog named Max once, but he passed away when I was a kid. &&&& Really? That is so sad. 0.999798595905304\n",
      "Checking two embeddings  I went for a long walk. &&&&  Oh, where did you go to? 0.9993966817855835\n",
      "Checking two embeddings Really? That is so sad. &&&&  Oh, where did you go to? 0.997349739074707\n",
      "Checking two embeddings Really? That is so sad. &&&& Yeah, it was tough losing him, but now Mila brings so much joy into my life. 0.0819339007139206\n",
      "Checking two embeddings  Oh, where did you go to? &&&&  To the pier. 0.9466522336006165\n",
      "Checking two embeddings Yeah, it was tough losing him, but now Mila brings so much joy into my life. &&&& I am so glad to hear that! 0.9986525177955627\n",
      "Checking two embeddings  To the pier. &&&&  Hmm, that's nice. 0.99994957447052\n"
     ]
    }
   ],
   "source": [
    "conversations: list[Conversation] = []\n",
    "\n",
    "time_tolerance = 0.13\n",
    "\n",
    "for t in transcript.history:\n",
    "    if len(conversations) == 0:\n",
    "        conversations.append(Conversation(t))\n",
    "        continue\n",
    "\n",
    "    # Checking if the person is part of any conversation\n",
    "    is_existing_member: bool = False\n",
    "    for c in conversations:\n",
    "        is_existing_member = is_existing_member or t.speaker in c.members\n",
    "\n",
    "    # else compare against all other options:\n",
    "    #dan los tiempos?\n",
    "    potential_c = {}\n",
    "    for idx, c in enumerate(conversations):\n",
    "        if t.timestamp[0] >= (c.last.timestamp[0] + (c.last.timestamp[1] - c.last.timestamp[0]) * (1 - time_tolerance)):\n",
    "            potential_c[idx] = check_two_embeddings(c.last.embedding, t.embedding)\n",
    "            print(\"Checking two embeddings\", c.last.text, \"&&&&\", t.text, potential_c[idx])\n",
    "            # print(potential_c)\n",
    "    \n",
    "    if len(potential_c)>0:\n",
    "        max_key = max(potential_c, key=lambda k: potential_c[k])\n",
    "        if potential_c[max_key] < 0.5 and is_existing_member is False:\n",
    "            print(max_key, t.text)\n",
    "            conversations.append(Conversation(t))\n",
    "        else:\n",
    "            conversations[max_key].add(t)\n",
    "\n",
    "    else:\n",
    "        conversations.append(Conversation(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SPEAKER_00 (0.0, 3.0):  Hello Antonio.\n",
      "0 SPEAKER_01 (3.0, 5.0):  Hey!\n",
      "0 SPEAKER_00 (5.0, 7.0):  How are you today?\n",
      "0 SPEAKER_01 (7.0, 9.0):  I'm good. You?\n",
      "0 SPEAKER_00 (9.0, 12.0):  I'm great. What did you do today?\n",
      "0 SPEAKER_01 (12.0, 15.0):  I went for a long walk.\n",
      "0 SPEAKER_00 (15.0, 17.0):  Oh, where did you go to?\n",
      "0 SPEAKER_01 (17.0, 19.0):  To the pier.\n",
      "0 SPEAKER_00 (19.0, 21.0):  Hmm, that's nice.\n",
      "1 Speaker A (1, 3): What's the name of your dog?\n",
      "1 Speaker B (3, 6): Her name is Mila, she is a bernaddoodle\n",
      "1 Speaker A (6, 9): Oh that is so cute! My dog's name is Max.\n",
      "1 Speaker B (9, 12): I had a dog named Max once, but he passed away when I was a kid.\n",
      "1 Speaker A (12, 15): Really? That is so sad.\n",
      "1 Speaker B (15, 18): Yeah, it was tough losing him, but now Mila brings so much joy into my life.\n",
      "1 Speaker A (18, 21): I am so glad to hear that!\n"
     ]
    }
   ],
   "source": [
    "for idx, c in enumerate(conversations):\n",
    "    for l in c.history:\n",
    "        print(idx, str(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me encantaria que asi como se va actualizando la lista de conversation members, \n",
    "# tener algo que yo pueda constantemente estar revisando si la gente nueva esta o no esta en la conversacion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
